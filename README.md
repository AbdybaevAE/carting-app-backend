## Описание проекта
Репозиторий содержит в себе 3 микросервиса.
Используемые технологии: 
* NodeJS
* SocketIO
* Redis
* MongoDb

Для демострационного запуска надо вызывать команду
```sh
docker-compose up
```
и дождаться поднятия всех сервисов.
По умолчания docker-compose рассматривает переменные из файла docker-compose.env

Для запуска в режиме разработки необходимо:
1. Создать файл .env в корне проекта и добавить все необходимые переменный(.env.sample - пример файла)
2. Установить зависимости
```sh
npm install
```
3. Запустить сервера:
```sh
npm run dev
```
## Общие идеи

Прежде чем приступить к разработке надо было понять в чем собственно идея

Сервис представляет из себя сайт на котором можно просматривать список пользователей с двумя кнопками создать нового пользователя и обновить результат выбранного пользователя. 

Идея проста, но нужно сделать это в режиме онлайн. То есть при обновлении данных, изменения будут подтягиваться по сокетам.

Первый вопрос который возник, это нужно ли делать пагинацию на страницу списка пользователей? 

Было решено сделать пагинацию по 10 пользователей на страницу(значение можно поменять в коде, не принципиально)
В следствие чего был принят данный факт как обязательный для при разработки сервиса. 

### Общие мысли
В таких "сервисах" обычно бывает много операции чтения и не много операции записи. Поэтому имеет смысл кэшировать страницы списка пользователей. То есть идея следующая: хранить список пользователей по определенной странице в кэше, и при изменении данных на текущей странице инвалидировать(удалять) кэш. Соответственно общая схема работы следующая:
Происходит запрос на сервер на список пользователей по определнной странице, далее проверяется данные кэша этой страницы, в случае отсутствия вычисляется и сохраняется кэш для данной страницы, далее идет ответ на запрос.
При изменении данных для страницы, кэш данной страницы удаляется. Таким образом будет поддерживаться всегда актуальный кэш. 

### Общая логика взаимодействия пользователя на клиентской части
Пользователь подключается к серверу. 
После подлючения клиент вызывает событие joinResponse, в качестве тела сообщения передает номер страницы по которой он(клиент) хочет получить список пользователей. Далее, сервер берет данные по списку пользователей и общему колличеству пользователей и emit-ит сообщение текущему клиенту. Помимо этого сервер подлючает данного клиента в room текущей старницы (хэш страницы в зависимости от ее номера). Соответсвенно при обнолвении данных на текущей старнице будет отсылаться сообщение всем подключенным сокетам в текущем room-е.
Помимо этого, при добалении нового пользователя, будет отсылаться сообщением всем подлюченным сокетам о том, что изменилось общее кол-во пользователей.

### Изменение страницы списка пользователей
Представим, что у нас есть сортированный возрастающий список пользователей[A1, A2..., An] в зависимости от результат(времени) заезда. Допустим, какой-то из пользователей улучашет свой результат. Пусть старая позиция пользователя K, новая позиция пользователя - S, тогда 1 <= S < K <= N. Допустим, что B1 - страница, в которой находится позиция S, Bm - страница, в которй находится позиция K. Тогда получается что изменятся все страницы на промежутке [B1, Bm], со сдвигом на 1 позицию.
Таже самая логика будет происходить при добавлении нового пользователя, только меняться будут страницы в промежутке [S,Q], где S - страница, куда попал новый пользователя, Q - последняя возможная страница. 
Поэтому было решено делать следующее - удалять из кэша все страницы затронутые при обновлении / создании пользователя

### Хранения сортированной последовательности пользователей
Для поддержания консистентности данных по вышеописанному списку при одновременных запросах было решено хранить этот список в редисе с использованием структуры данных SortedSet. Почему именно он? Данная структура поддерживает хранение списка данных с использованием ранкинга, где данные - id пользователя, ранкнинг - время заезда пользователя.
Добавление пользователя происходит за O(log(n))
Чтение  - O(log(n) + m), где m - колличество последовательных пользователей которые надо прочитать от определенной позиции. 
Данное решение будет быстро работать, при больших N.
Получается что, при запросе какой либо странице которая отсутсвует в кэше, будет брать соответственный промежуток id пользователей [p,q] из этой последовательности, обогащать данными(тоже из кэша) и отдавать клиенту

### Масштабирование
Так как могут происходить одновременные запросы на мутирование списка, то было решено использовать библиотеку redlock в качестве Distributed Lock. То есть прежде чем менять спискок, будем его локать, после менять и потом освобождать.
Редис достаточно легко масштабировать в данной схеме. Мы можем хранить данные пользователей по разным инстансам редиса(например в зависимоти от userId). Сортированный список из id пользователей - массив из стрингов, который не занимает много памяти. Ну и также хранить страницы по ранзным инстансам редиса. В целом ожидается много операций чтения, которые тоже можно распределить на разные инстансы. 

Как мастштабировать сокеты? Можно использовать балансер и sticky session
Помимо этого есть библиотека для масштабирования сокета через редис(на базе socket.io + adapter). Помимо этого есть библиотека для работы с сокетом из не сокет процесса. Но было решено использовать библиотеку socket.io. Варианты в общем есть.

### Как просходит конкретное обновлении данных пользователя:
1. Запрос падает на сервер
2. Сервер обновляет упорядоченный SortedSet
3. Вычиляются старая и новая позиция пользователя(a,b)
4. Удаляются из кэша все страницы в промежутке позиции [a,b]
5. Отправляется сообщение об обновлени страниц на промежутке от [a,b] в канал с использованием redis pub/sub
6. Все подписавшиеся инстансы сервера получают сообщение об обнолвении страниц
7. В случае если сервер имеет сокет подписанный на ту или иную старницу из промежутка [a,b], высылается сообщеним подсписавшимся сокетам(по каналам) об обновлении старницы.
Кто первый получит сообещние, тот и вычислит кэш и сохранит его. Обработчики, появившиеся позже не будут вычислять кэш.
Примерно такая, же логика при добавлении нового пользователя

Хранить сокеты будет в Map(в процессе NodeJs). где ключ - room страницы, значение - Set из строк id сокетов. Поэтому при определенных событиях(connect, setPage, disconnet) будет производить соотвествующие действия над этим мап-ом

Тут же если новая позиция пользователя - 0, это значит, что пользователь лидер, и будем отправлять в redis канал сообщение об обновлении лидера заезда(данные будут включать в себя первого и второго пользователя с SortedSet)

Получается, что email service будет работать через pub/sub redis. Нужно учется, чтобы не было дублирующихся сообщение при несколькоих экземплярах(подписчиках на этот канал) сервиса

### Архитектура 
* Для того, чтобы работать с промежутками использутся класс Span(lib/span.js). Там есть такие полезные функции createFromHash, getBounds, createFromPoint.
* Для того, чтобы работать с клиентским представлением Span-a используется PageAdapter(lib/span.js)

* Для взаимодействия с сокетом - SocketManager(lib/socket-manager.js). Класс представляет обработчки событий при том или ином действии. 

* Для трэкинга, какой сокет присоеденился или отсоединился от канала, используется класс SocketTracker.

* Для взаимодействия с кэшом на уровне создать спан пользователей, удалить спан пользователей, отправить сообщение в редис, создать кэш пользователя используется класс CacheManager.

* Есть "service" api, который принимает http и веб сокет.
* Для обновления / создания пользователя вызываеются "actions" сервиса "users"
* Сервис "users" используется для обработки запросов от api сервиса и создания кэша
* Сервис "email" представляет из себя одиночный подписчик redis-a, который отсылает сообщения(sendgrid + pug) на почту исходя из тела сообщения

### В целом был сделан упор на масштибрование и оптимизацию системы. 

Для того, чтобы получить email сообщение о победителе, нужно поменять в переменной окружения значение TEST_EMAIL на нужный email.

### Что нужно сделать чтобы запустить проект?
1. docker-compose up(дефолтный порт бэкенда - 3000)
2. запустить фронтенд(дефолтный порт - 4000)
3. Открыть http://localhost:4000