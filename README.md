## Описание проекта
Репозиторий содержит в себе 3 микросервиса.
Используемые технологии: 
* NodeJS
* SocketIO
* Redis
* MongoDb

Для демострационного запуска надо выполнить команду и дождаться поднятия всех сервисов(дождаться пока консоль не устаканится).
```sh
docker-compose up
```

По умолчания docker-compose рассматривает переменные из файла docker-compose.env

Для запуска в режиме разработки необходимо:
1. Создать файл .env в корне проекта и добавить все необходимые переменные(.env.sample - пример файла)
2. Установить зависимости
```sh
npm install
```
3. Запустить все сервисы командой
```sh
npm run dev
```

## Общие идеи

Прежде чем приступить к разработке надо было понять в чем собственно стоит задача.
Сервис представляет из себя сайт на котором можно просматривать список пользователей с двумя кнопками: создать нового пользователя и обновить результат выбранного пользователя. 
Идея проста, но нужно сделать это в режиме онлайн. То есть при обновлении данных, изменения будут подтягиваться по сокету.
Первый вопрос который возник, это нужно ли делать пагинацию на страницу списка пользователей? 
Было решено сделать пагинацию в размере 10 пользователей на страницу(значение можно поменять в коде, не принципиально)
В следствие чего был принят данный факт как обязательный при разработке. 

### Общие мысли

В таком сервисе обычно бывает много операции чтения и не много операции записи. Поэтому имеет смысл кэшировать страницы списка пользователей. То есть идея следующая: хранить список пользователей по определенной странице в кэше, и при изменении данных на этой странице удалять кэш. Соответственно общая схема работы следующая:
Происходит запрос на сервер на список пользователей по определенной странице, далее проверяется данные о наличии кэша по этой страницы, в случае отсутствия вычисляется и сохраняется кэш для данной страницы, далее идет ответ на запрос.
При изменении данных для страницы, кэш данной страницы удаляется. Таким образом будет поддерживаться всегда актуальный кэш. 

### Общая логика взаимодействия пользователя на клиентской части

Пользователь подключается к серверу. 
После подлючения клиент emit-ит событие setPage. В сообщении передается номер страницы по которой он(клиент) хочет получить список пользователей. Далее, сервер берет данные по списку пользователей и общему колличеству пользователей и emit-ит сообщение текущему клиенту. Помимо этого сервер подлючает данного клиента в room текущей старницы(хэш страницы в зависимости от ее номера). Соответственно при обновлении данных на текущей старнице будет отсылаться сообщение всем подключенным сокетам в текущем room-е.
Помимо этого, при добалении нового пользователя, будет отсылаться сообщение всем подлюченным сокетам о том, что изменилось общее кол-во пользователей.

### Изменение страницы списка пользователей

Представим, что у нас есть сортированный возрастающий список пользователей[A1, A2..., An] в зависимости от результат(времени) заезда. Допустим, какой-то из пользователей улучшает свой результат. Пусть старая позиция пользователя K, новая позиция пользователя - S, тогда 1 <= S < K <= N. Допустим, что B1 - страница в которой находится позиция S, Bm - страница, в которой находится позиция K. Тогда получается, что изменятся все страницы на промежутке [B1, Bm], со сдвигом на 1 позицию.
Таже самая логика будет происходить при добавлении нового пользователя, только меняться будут страницы в промежутке [S,Q], где S - страница, куда попал новый пользователя, Q - последняя возможная страница. 
Поэтому было решено делать следующее - удалять из кэша все страницы затронутые при обновлении / создании пользователя.

### Хранения сортированной последовательности пользователей

Для поддержания консистентности данных по вышеописанному списку при одновременных запросах было решено хранить этот список в редисе с использованием структуры данных SortedSet. Почему именно он? Данная структура поддерживает хранение списка данных с использованием ранкинга, где данные - id пользователя, ранкнинг - время заезда пользователя.
Добавление пользователя происходит за O(log(n)).
Чтение  - O(log(n) + m), где m - колличество последовательных пользователей которые надо прочитать от определенной позиции. 
Данное решение будет быстро работать даже при больших n.
Получается что, при запросе какой-либо страницы которая отсутствует в кэше, будет вычисляться соответственный промежуток id пользователей [p,q] из этой последовательности, обогащаться данными(тоже из кэша) и отдаватьcz клиенту.

### Масштабирование

Так как могут происходить одновременные запросы на мутирование списка, то было решено использовать библиотеку redlock в качестве distributed lock. То есть прежде чем менять спискок, будем его локать, менять и только потом освобождать.
Редис достаточно легко масштабировать в данной схеме. Мы можем хранить данные пользователей по разным инстансам редиса(например в зависимоти от userId). Сортированный список из id пользователей - массив из стрингов, который не занимает много памяти. Ну и также хранить страницы по разным инстансам редиса. В целом ожидается много операций чтения, которые тоже можно распределить на разные инстансы. 

Как мастштабировать сокеты? Можно использовать балансер и sticky session.
Помимо этого есть библиотека для масштабирования сокета через редис(на базе socket.io + adapter). Помимо этого есть библиотека для работы с сокетом из не сокет процесса. Но было решено использовать библиотеку socket.io. Варианты в общем есть.

### Алгоритм обновления результата пользователя:
1. Запрос падает на сервер
2. Сервер обновляет упорядоченный SortedSet
3. Вычиляются старая и новая позиция пользователя(a,b) в SortedSet
4. Удаляются из кэша все страницы в промежутке [a,b]
5. Отправляется сообщение об обновлении страниц на промежутке от [a,b] в канал с использованием redis pub/sub.
6. Все подписавшиеся инстансы сервера получают сообщение об обновлении страниц
7. В случае если сервер имеет сокет подписанный на ту или иную страницу из промежутка [a,b], обновляется кэш страницы и высылается сообщение подсписавшимся сокетам(по каналам) об обновлении старницы.

Кто первый получит сообщение, тот и вычислит кэш и сохранит его. Обработчики, появившиеся позже не будут вычислять кэш.
Примерно такая, же логика при добавлении нового пользователя.

Хранить сокеты будем в Map(в процессе NodeJs), где ключ - room страницы, значение - Set из строк id сокетов. Поэтому при определенных событиях(connect, setPage, disconnet) будем производить соответствующие действия над этим map-ом.

Тут же если новая позиция пользователя - 0, это значит, что пользователь лидер, и будем отправлять в redis канал сообщение об обновлении лидера заезда(данные будут включать в себя первого и второго пользователя из SortedSet).

Получается, что email service будет работать через pub/sub redis. Нужно учесть в дальнейшем, чтобы не было дублирующихся сообщение при нескольких экземплярах(подписчиках на этот канал) сервиса.

### Архитектура 
* Для того, чтобы работать с промежутками использутся класс Span(lib/span.js). Там есть такие полезные функции как createFromHash, getBounds, createFromPoint.
* Для того, чтобы работать с клиентским представлением Span-a используется PageAdapter(lib/span.js)

* Для взаимодействия с сокетом - SocketManager(lib/socket-manager.js). Класс представляет обработчик событий при том или ином действии. 

* Для трэкинга, какой сокет присоеденился или отсоединился от канала, используется класс SocketTracker.

* Для взаимодействия с кэшом на уровне: создать спан пользователей, удалить спан пользователей, отправить сообщение в редис, создать кэш пользователя используется класс CacheManager.

* Есть "service" api, который принимает http и веб сокет.
* Для обновления / создания пользователя вызываются "actions" сервиса "users"
* Сервис "users" используется для обработки запросов от api сервиса и создания кэша
* Сервис "email" представляет из себя одиночный подписчик redis-a, который отсылает сообщения(sendgrid + pug) на почту исходя из тела сообщения

### В целом был сделан упор на масштибрование и оптимизацию системы. 

Для того, чтобы получить email сообщение о победителе, нужно поменять в переменной окружения значение TEST_EMAIL на нужный email.

### Что нужно сделать чтобы запустить проект?
1. docker-compose up(дефолтный порт бэкенда - 3000)
2. запустить фронтенд(дефолтный порт - 4000)
3. Открыть http://localhost:4000
